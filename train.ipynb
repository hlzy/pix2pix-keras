{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from generator import UNETGenerator\n",
    "from keras.layers import Activation, Input, Dropout, merge,concatenate\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.layers import Conv2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# HYPER PARAMS\n",
    "# ---------------------------------------------\n",
    "# width, height of images to work with. Assumes images are square\n",
    "im_width = im_height = 256\n",
    "\n",
    "# inpu/oputputt channels in image\n",
    "input_channels = 3\n",
    "output_channels = 3\n",
    "\n",
    "# image dims\n",
    "input_img_dim = (im_width, im_height,input_channels)\n",
    "output_img_dim = (im_width, im_height,output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNETGenerator(input_img_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Creates the generator according to the specs in the paper below.\n",
    "    It's basically a skip layer AutoEncoder\n",
    "    Generator does the following:\n",
    "    1. Takes in an image\n",
    "    2. Generates an image from this image\n",
    "    Differs from a standard GAN because the image isn't random.\n",
    "    This model tries to learn a mapping from a suboptimal image to an optimal image.\n",
    "    [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "    :param input_img_dim: (channel, height, width)\n",
    "    :param output_img_dim: (channel, height, width)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # -------------------------------\n",
    "    # ENCODER\n",
    "    # C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    # 1 layer block = Conv - BN - LeakyRelu\n",
    "    # -------------------------------\n",
    "    stride = 2\n",
    "    merge_mode = 'concat'\n",
    "\n",
    "    # batch norm mode\n",
    "    bn_mode = 2\n",
    "\n",
    "    # batch norm merge axis\n",
    "    bn_axis = 3\n",
    "    bn_axis_1 = 3\n",
    "\n",
    "    input_layer = Input(shape=input_img_dim, name=\"unet_input\")\n",
    "\n",
    "    # 1 encoder C64\n",
    "    # skip batchnorm on this layer on purpose (from paper)\n",
    "    en_1 = Convolution2D(nb_filter=64, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(input_layer)\n",
    "    #en_1 = Conv2D(filters=64,kernel_size=4,padding=\"same\",strides=2)(input_layer)\n",
    "    en_1 = LeakyReLU(alpha=0.2)(en_1)\n",
    "\n",
    "#     # 2 encoder C128\n",
    "    en_2 = Convolution2D(nb_filter=64, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_1)\n",
    "    #en_2 = Conv2D(filters=64,kernel_size=4,padding=\"same\",strides=2)(en_1)\n",
    "    en_2 = BatchNormalization(name='gen_en_bn_2', axis=bn_axis)(en_2)\n",
    "    en_2 = LeakyReLU(alpha=0.2)(en_2)\n",
    "\n",
    "    # 3 encoder C256\n",
    "    en_3 = Convolution2D(nb_filter=256, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_2)\n",
    "    en_3 = BatchNormalization(name='gen_en_bn_3', axis=bn_axis)(en_3)\n",
    "    en_3 = LeakyReLU(alpha=0.2)(en_3)\n",
    "\n",
    "    # 4 encoder C512\n",
    "    en_4 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_3)\n",
    "    en_4 = BatchNormalization(name='gen_en_bn_4', axis=bn_axis)(en_4)\n",
    "    en_4 = LeakyReLU(alpha=0.2)(en_4)\n",
    "\n",
    "    # 5 encoder C512\n",
    "    en_5 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_4)\n",
    "    en_5 = BatchNormalization(name='gen_en_bn_5', axis=bn_axis)(en_5)\n",
    "    en_5 = LeakyReLU(alpha=0.2)(en_5)\n",
    "\n",
    "    # 6 encoder C512\n",
    "    en_6 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_5)\n",
    "    en_6 = BatchNormalization(name='gen_en_bn_6', axis=bn_axis)(en_6)\n",
    "    en_6 = LeakyReLU(alpha=0.2)(en_6)\n",
    "\n",
    "    # 7 encoder C512\n",
    "    en_7 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_6)\n",
    "    en_7 = BatchNormalization(name='gen_en_bn_7', axis=bn_axis)(en_7)\n",
    "    en_7 = LeakyReLU(alpha=0.2)(en_7)\n",
    "\n",
    "    # 8 encoder C512\n",
    "    en_8 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_7)\n",
    "    en_8 = BatchNormalization(name='gen_en_bn_8', axis=bn_axis)(en_8)\n",
    "    en_8 = LeakyReLU(alpha=0.2)(en_8)\n",
    "    \n",
    "#    unet_generator = Model(input=[input_layer], output=[en_8], name='unet_generator')\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # DECODER\n",
    "    # CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    # 1 layer block = Conv - Upsample - BN - DO - Relu\n",
    "    # also adds skip connections (merge). Takes input from previous layer matching encoder layer\n",
    "    # -------------------------------\n",
    "    # 1 decoder CD512 (decodes en_8)\n",
    "    de_1 = UpSampling2D(size=(2, 2))(en_8)\n",
    "    de_1 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same')(de_1)\n",
    "    de_1 = BatchNormalization(name='gen_de_bn_1', axis=bn_axis)(de_1)\n",
    "    de_1 = Dropout(p=0.5)(de_1)\n",
    "    #de_1 = merge([de_1, en_7], mode=merge_mode, concat_axis=1)\n",
    "    de_1 = concatenate([de_1, en_7],axis = bn_axis_1)\n",
    "    de_1 = Activation('relu')(de_1)\n",
    "\n",
    "    # 2 decoder CD1024 (decodes en_7)\n",
    "    de_2 = UpSampling2D(size=(2, 2))(de_1)\n",
    "    de_2 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_2)\n",
    "    de_2 = BatchNormalization(name='gen_de_bn_2', axis=bn_axis)(de_2)\n",
    "    de_2 = Dropout(p=0.5)(de_2)\n",
    "    #de_2 = merge([de_2, en_6], mode=merge_mode, concat_axis=1)\n",
    "    de_2 = concatenate([de_2, en_6],axis = bn_axis_1)\n",
    "    de_2 = Activation('relu')(de_2)\n",
    "\n",
    "    # 3 decoder CD1024 (decodes en_6)\n",
    "    de_3 = UpSampling2D(size=(2, 2))(de_2)\n",
    "    de_3 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_3)\n",
    "    de_3 = BatchNormalization(name='gen_de_bn_3', axis=bn_axis)(de_3)\n",
    "    de_3 = Dropout(p=0.5)(de_3)\n",
    "    #de_3 = merge([de_3, en_5], mode=merge_mode, concat_axis=1)\n",
    "    de_3 = concatenate([de_3, en_5],axis = bn_axis_1)\n",
    "    de_3 = Activation('relu')(de_3)\n",
    "\n",
    "    # 4 decoder CD1024 (decodes en_5)\n",
    "    de_4 = UpSampling2D(size=(2, 2))(de_3)\n",
    "    de_4 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_4)\n",
    "    de_4 = BatchNormalization(name='gen_de_bn_4', axis=bn_axis)(de_4)\n",
    "    de_4 = Dropout(p=0.5)(de_4)\n",
    "    #de_4 = merge([de_4, en_4], mode=merge_mode, concat_axis=1)\n",
    "    de_4 = concatenate([de_4, en_4],axis = bn_axis_1)\n",
    "    de_4 = Activation('relu')(de_4)\n",
    "\n",
    "    # 5 decoder CD1024 (decodes en_4)\n",
    "    de_5 = UpSampling2D(size=(2, 2))(de_4)\n",
    "    de_5 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_5)\n",
    "    de_5 = BatchNormalization(name='gen_de_bn_5', axis=bn_axis)(de_5)\n",
    "    de_5 = Dropout(p=0.5)(de_5)\n",
    "    #de_5 = merge([de_5, en_3], mode=merge_mode, concat_axis=1)\n",
    "    de_5 = concatenate([de_5, en_3],axis = bn_axis_1)\n",
    "    de_5 = Activation('relu')(de_5)\n",
    "\n",
    "    # 6 decoder C512 (decodes en_3)\n",
    "    de_6 = UpSampling2D(size=(2, 2))(de_5)\n",
    "    de_6 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same')(de_6)\n",
    "    de_6 = BatchNormalization(name='gen_de_bn_6', axis=bn_axis)(de_6)\n",
    "    de_6 = Dropout(p=0.5)(de_6)\n",
    "    #de_6 = merge([de_6, en_2], mode=merge_mode, concat_axis=1)\n",
    "    de_6 = concatenate([de_6, en_2],axis = bn_axis_1)\n",
    "    de_6 = Activation('relu')(de_6)\n",
    "\n",
    "    # 7 decoder CD256 (decodes en_2)\n",
    "    de_7 = UpSampling2D(size=(2, 2))(de_6)\n",
    "    de_7 = Convolution2D(nb_filter=256, nb_row=4, nb_col=4, border_mode='same')(de_7)\n",
    "    de_7 = BatchNormalization(name='gen_de_bn_7', axis=bn_axis)(de_7)\n",
    "    de_7 = Dropout(p=0.5)(de_7)\n",
    "    #de_7 = merge([de_7, en_1], mode=merge_mode, concat_axis=1)\n",
    "    de_7 = concatenate([de_7, en_1],axis = bn_axis_1)\n",
    "    de_7 = Activation('relu')(de_7)\n",
    "\n",
    "    # After the last layer in the decoder, a convolution is applied\n",
    "    # to map to the number of output channels (3 in general,\n",
    "    # except in colorization, where it is 2), followed by a Tanh\n",
    "    # function.\n",
    "    de_8 = UpSampling2D(size=(2, 2))(de_7)\n",
    "    de_8 = Convolution2D(nb_filter=num_output_channels, nb_row=4, nb_col=4, border_mode='same')(de_8)\n",
    "    de_8 = Activation('tanh')(de_8)\n",
    "\n",
    "    unet_generator = Model(input=[input_layer], output=[de_8], name='unet_generator')\n",
    "    return unet_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=256, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:105: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:121: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:123: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:132: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=3, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:154: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"unet_generator\", inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "generator_nn = UNETGenerator(input_img_dim=input_img_dim, num_output_channels=output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet_generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "unet_input (InputLayer)         (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 3136        unet_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   65600       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_2 (BatchNormalization (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 64)   0           gen_en_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 256)  262400      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_3 (BatchNormalization (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 256)  0           gen_en_bn_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_4 (BatchNormalization (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           gen_en_bn_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 512)    4194816     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_5 (BatchNormalization (None, 8, 8, 512)    2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 512)    0           gen_en_bn_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 512)    4194816     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_6 (BatchNormalization (None, 4, 4, 512)    2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 512)    0           gen_en_bn_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 2, 512)    4194816     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_7 (BatchNormalization (None, 2, 2, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 2, 2, 512)    0           gen_en_bn_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 512)    4194816     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_8 (BatchNormalization (None, 1, 1, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1, 1, 512)    0           gen_en_bn_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 2, 2, 512)    0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 2, 512)    4194816     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_1 (BatchNormalization (None, 2, 2, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 2, 512)    0           gen_de_bn_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 1024)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2, 2, 1024)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 4, 4, 1024)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 1024)   16778240    up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_2 (BatchNormalization (None, 4, 4, 1024)   4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 1024)   0           gen_de_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 1536)   0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4, 4, 1536)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 1536)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 1024)   25166848    up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_3 (BatchNormalization (None, 8, 8, 1024)   4096        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 1024)   0           gen_de_bn_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 1536)   0           dropout_3[0][0]                  \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 1536)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 1536) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 1024) 25166848    up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_4 (BatchNormalization (None, 16, 16, 1024) 4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 1024) 0           gen_de_bn_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1536) 0           dropout_4[0][0]                  \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 1536) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 1536) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 1024) 25166848    up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_5 (BatchNormalization (None, 32, 32, 1024) 4096        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 1024) 0           gen_de_bn_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 1280) 0           dropout_5[0][0]                  \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 1280) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 1280) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 512)  10486272    up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_6 (BatchNormalization (None, 64, 64, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 64, 512)  0           gen_de_bn_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 576)  0           dropout_6[0][0]                  \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 576)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 576 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 256 2359552     up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_7 (BatchNormalization (None, 128, 128, 256 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 128, 256 0           gen_de_bn_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 320 0           dropout_7[0][0]                  \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 320 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 320 0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 3)  15363       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256, 256, 3)  0           conv2d_16[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 128,575,875\n",
      "Trainable params: 128,559,363\n",
      "Non-trainable params: 16,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt_discriminator = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "generator_nn.compile(loss='mae', optimizer=opt_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "ban_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_imdb(cur_ban):\n",
    "    cur_ban = (cur_ban + 1) % ban_num\n",
    "    fid = open(os.path.join(\"pic_db\",\"test_{ban_index}_pic.imdb\".format(ban_index=cur_ban)),'rb')\n",
    "    print(\"read...\")\n",
    "    train_data = pickle.load(fid)\n",
    "    #train_data = train_data[0] #只取一行做测试\n",
    "    fid.close()\n",
    "    print(\"finist...\")\n",
    "    random.shuffle(train_data)\n",
    "    print(\"shuffle\")\n",
    "    tmp_list = np.array(train_data)\n",
    "    a = tmp_list[:,0].tolist()\n",
    "    b = np.copy(a)  #如果不进行copy会出现pickle的实际未释放的情况\n",
    "    c = tmp_list[:,1].tolist()\n",
    "    d = np.copy(c)  #如果不进行copy会出现pickle的实际未释放的情况\n",
    "    #share_rate = np.copy(tmp_list[:,1])\n",
    "    return b,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read...\n",
      "finist...\n",
      "shuffle\n"
     ]
    }
   ],
   "source": [
    "origin_image,true_iamge = load_imdb(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read...\n",
      "finist...\n",
      "shuffle\n",
      "read...\n",
      "finist...\n",
      "shuffle\n",
      "read...\n",
      "finist...\n",
      "shuffle\n"
     ]
    }
   ],
   "source": [
    "for ban_i in range(1,ban_num+1):\n",
    "    origin_image_tmp,true_iamge_tmp = load_imdb(ban_i)\n",
    "    origin_image =np.concatenate((origin_image,origin_image_tmp),axis=0)\n",
    "    true_iamge   =np.concatenate((true_iamge,true_iamge_tmp),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(140, 256, 256, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/1.jpg\")\n",
    "my_pic=  my_pic[:,256:,:]\n",
    "my_pic = my_pic.reshape(1,256,256,3)\n",
    "my_pic = (my_pic - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start trining\n",
      "epoch:0 loss:0.3254384994506836\n",
      "epoch:1 loss:0.3176042139530182\n",
      "epoch:2 loss:0.31377631425857544\n",
      "epoch:3 loss:0.31339138746261597\n",
      "epoch:4 loss:0.3363170027732849\n",
      "epoch:5 loss:0.3224816620349884\n",
      "epoch:6 loss:0.2908821105957031\n",
      "epoch:7 loss:0.27234604954719543\n",
      "epoch:8 loss:0.2780560255050659\n",
      "epoch:9 loss:0.2716536521911621\n",
      "epoch:10 loss:0.25083160400390625\n",
      "epoch:11 loss:0.24529194831848145\n",
      "epoch:12 loss:0.2345253825187683\n",
      "epoch:13 loss:0.2251906394958496\n",
      "epoch:14 loss:0.2258196771144867\n",
      "epoch:15 loss:0.21541914343833923\n",
      "epoch:16 loss:0.21403232216835022\n",
      "epoch:17 loss:0.20579148828983307\n",
      "epoch:18 loss:0.20264554023742676\n",
      "epoch:19 loss:0.20167535543441772\n",
      "epoch:20 loss:0.20079845190048218\n",
      "epoch:21 loss:0.20113429427146912\n",
      "epoch:22 loss:0.18439555168151855\n",
      "epoch:23 loss:0.18668556213378906\n",
      "epoch:24 loss:0.17498531937599182\n",
      "epoch:25 loss:0.1756925880908966\n",
      "epoch:26 loss:0.17154327034950256\n",
      "epoch:27 loss:0.1757306456565857\n",
      "epoch:28 loss:0.17586392164230347\n",
      "epoch:29 loss:0.16926594078540802\n",
      "epoch:30 loss:0.16930001974105835\n",
      "epoch:31 loss:0.16287566721439362\n",
      "epoch:32 loss:0.16776929795742035\n",
      "epoch:33 loss:0.1629548966884613\n",
      "epoch:34 loss:0.16135188937187195\n",
      "epoch:35 loss:0.16332805156707764\n",
      "epoch:36 loss:0.15744559466838837\n",
      "epoch:37 loss:0.15848645567893982\n",
      "epoch:38 loss:0.16468104720115662\n",
      "epoch:39 loss:0.1591942310333252\n",
      "epoch:40 loss:0.15279191732406616\n",
      "epoch:41 loss:0.1526792347431183\n",
      "epoch:42 loss:0.1518150418996811\n",
      "epoch:43 loss:0.15063607692718506\n",
      "epoch:44 loss:0.14889687299728394\n",
      "epoch:45 loss:0.14848282933235168\n",
      "epoch:46 loss:0.1448373943567276\n",
      "epoch:47 loss:0.14361637830734253\n",
      "epoch:48 loss:0.1488628089427948\n",
      "epoch:49 loss:0.14251405000686646\n",
      "epoch:50 loss:0.14404179155826569\n",
      "epoch:51 loss:0.1437849998474121\n",
      "epoch:52 loss:0.1414610892534256\n",
      "epoch:53 loss:0.1385907530784607\n",
      "epoch:54 loss:0.13987571001052856\n",
      "epoch:55 loss:0.13795338571071625\n",
      "epoch:56 loss:0.14358800649642944\n",
      "epoch:57 loss:0.13821697235107422\n",
      "epoch:58 loss:0.1363549530506134\n",
      "epoch:59 loss:0.14029355347156525\n",
      "epoch:60 loss:0.1380137801170349\n",
      "epoch:61 loss:0.13787564635276794\n",
      "epoch:62 loss:0.13347241282463074\n",
      "epoch:63 loss:0.13208892941474915\n",
      "epoch:64 loss:0.13188302516937256\n",
      "epoch:65 loss:0.13705313205718994\n",
      "epoch:66 loss:0.13109537959098816\n",
      "epoch:67 loss:0.13081979751586914\n",
      "epoch:68 loss:0.13320276141166687\n",
      "epoch:69 loss:0.13132530450820923\n",
      "epoch:70 loss:0.12887439131736755\n",
      "epoch:71 loss:0.12757307291030884\n",
      "epoch:72 loss:0.1298467516899109\n",
      "epoch:73 loss:0.12566116452217102\n",
      "epoch:74 loss:0.1280580461025238\n",
      "epoch:75 loss:0.12763679027557373\n",
      "epoch:76 loss:0.12689639627933502\n",
      "epoch:77 loss:0.13995671272277832\n",
      "epoch:78 loss:0.12325749546289444\n",
      "epoch:79 loss:0.1224900335073471\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7887d616a9fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#         #break\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morigin_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mdisc_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtrue_iamge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morigin_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mgenerator_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"b_a_model_{}.h5\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/Keras-2.3.1-py3.6.egg/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1512\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1514\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1516\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3734\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3735\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3736\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3737\u001b[0m         expand_composites=True)\n\u001b[1;32m   3738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   3734\u001b[0m     return nest.pack_sequence_as(\n\u001b[1;32m   3735\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_outputs_structure\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3736\u001b[0;31m         \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3737\u001b[0m         expand_composites=True)\n\u001b[1;32m   3738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    906\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    909\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epoch=100\n",
    "print(\"start trining\")\n",
    "for epoch in range(0, nb_epoch):\n",
    "#     for ban_i in range(0,ban_num):\n",
    "#         origin_image,true_iamge = load_imdb(ban_i)\n",
    "#         #break\n",
    "        for i in range(origin_image.shape[0]):\n",
    "            disc_loss = generator_nn.train_on_batch( true_iamge[i:i+1],origin_image[i:i+1])\n",
    "        if epoch % 10 == 9:\n",
    "            generator_nn.save_weights(\"b_a_model_{}.h5\".format(epoch))\n",
    "            fake_pic = generator_nn.predict(my_pic)\n",
    "            fake_pic = fake_pic * 127.5 + 127.5\n",
    "            cv2.imwrite(\"result_{}.jpg\".format(epoch),fake_pic[0])\n",
    "        print(\"epoch:{} loss:{}\".format(epoch,disc_loss))\n",
    "    #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/5.jpg\")\n",
    "my_pic=  my_pic[:,256:,:]\n",
    "my_pic = my_pic.reshape(1,256,256,3)\n",
    "my_pic = (my_pic - 127.5) / 127.5\n",
    "fake_pic = generator_nn.predict(my_pic)\n",
    "fake_pic = fake_pic * 127.5 + 127.5\n",
    "cv2.imwrite(\"result.jpg\".format(epoch),fake_pic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
