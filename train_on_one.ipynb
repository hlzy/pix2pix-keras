{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from generator import UNETGenerator\n",
    "from keras.layers import Activation, Input, Dropout, merge,concatenate\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.layers import Conv2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# HYPER PARAMS\n",
    "# ---------------------------------------------\n",
    "# width, height of images to work with. Assumes images are square\n",
    "im_width = im_height = 256\n",
    "\n",
    "# inpu/oputputt channels in image\n",
    "input_channels = 3\n",
    "output_channels = 3\n",
    "\n",
    "# image dims\n",
    "input_img_dim = (im_width, im_height,input_channels)\n",
    "output_img_dim = (im_width, im_height,output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNETGenerator(input_img_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Creates the generator according to the specs in the paper below.\n",
    "    It's basically a skip layer AutoEncoder\n",
    "    Generator does the following:\n",
    "    1. Takes in an image\n",
    "    2. Generates an image from this image\n",
    "    Differs from a standard GAN because the image isn't random.\n",
    "    This model tries to learn a mapping from a suboptimal image to an optimal image.\n",
    "    [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "    :param input_img_dim: (channel, height, width)\n",
    "    :param output_img_dim: (channel, height, width)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # -------------------------------\n",
    "    # ENCODER\n",
    "    # C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    # 1 layer block = Conv - BN - LeakyRelu\n",
    "    # -------------------------------\n",
    "    stride = 2\n",
    "    merge_mode = 'concat'\n",
    "\n",
    "    # batch norm mode\n",
    "    bn_mode = 2\n",
    "\n",
    "    # batch norm merge axis\n",
    "    bn_axis = 3\n",
    "    bn_axis_1 = 3\n",
    "\n",
    "    input_layer = Input(shape=input_img_dim, name=\"unet_input\")\n",
    "\n",
    "    # 1 encoder C64\n",
    "    # skip batchnorm on this layer on purpose (from paper)\n",
    "    en_1 = Convolution2D(nb_filter=64, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(input_layer)\n",
    "    #en_1 = Conv2D(filters=64,kernel_size=4,padding=\"same\",strides=2)(input_layer)\n",
    "    en_1 = LeakyReLU(alpha=0.2)(en_1)\n",
    "\n",
    "#     # 2 encoder C128\n",
    "    en_2 = Convolution2D(nb_filter=64, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_1)\n",
    "    #en_2 = Conv2D(filters=64,kernel_size=4,padding=\"same\",strides=2)(en_1)\n",
    "    en_2 = BatchNormalization(name='gen_en_bn_2', axis=bn_axis)(en_2)\n",
    "    en_2 = LeakyReLU(alpha=0.2)(en_2)\n",
    "\n",
    "    # 3 encoder C256\n",
    "    en_3 = Convolution2D(nb_filter=256, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_2)\n",
    "    en_3 = BatchNormalization(name='gen_en_bn_3', axis=bn_axis)(en_3)\n",
    "    en_3 = LeakyReLU(alpha=0.2)(en_3)\n",
    "\n",
    "    # 4 encoder C512\n",
    "    en_4 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_3)\n",
    "    en_4 = BatchNormalization(name='gen_en_bn_4', axis=bn_axis)(en_4)\n",
    "    en_4 = LeakyReLU(alpha=0.2)(en_4)\n",
    "\n",
    "    # 5 encoder C512\n",
    "    en_5 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_4)\n",
    "    en_5 = BatchNormalization(name='gen_en_bn_5', axis=bn_axis)(en_5)\n",
    "    en_5 = LeakyReLU(alpha=0.2)(en_5)\n",
    "\n",
    "    # 6 encoder C512\n",
    "    en_6 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_5)\n",
    "    en_6 = BatchNormalization(name='gen_en_bn_6', axis=bn_axis)(en_6)\n",
    "    en_6 = LeakyReLU(alpha=0.2)(en_6)\n",
    "\n",
    "    # 7 encoder C512\n",
    "    en_7 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_6)\n",
    "    en_7 = BatchNormalization(name='gen_en_bn_7', axis=bn_axis)(en_7)\n",
    "    en_7 = LeakyReLU(alpha=0.2)(en_7)\n",
    "\n",
    "    # 8 encoder C512\n",
    "    en_8 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_7)\n",
    "    en_8 = BatchNormalization(name='gen_en_bn_8', axis=bn_axis)(en_8)\n",
    "    en_8 = LeakyReLU(alpha=0.2)(en_8)\n",
    "    \n",
    "#    unet_generator = Model(input=[input_layer], output=[en_8], name='unet_generator')\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # DECODER\n",
    "    # CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    # 1 layer block = Conv - Upsample - BN - DO - Relu\n",
    "    # also adds skip connections (merge). Takes input from previous layer matching encoder layer\n",
    "    # -------------------------------\n",
    "    # 1 decoder CD512 (decodes en_8)\n",
    "    de_1 = UpSampling2D(size=(2, 2))(en_8)\n",
    "    de_1 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same')(de_1)\n",
    "    de_1 = BatchNormalization(name='gen_de_bn_1', axis=bn_axis)(de_1)\n",
    "    de_1 = Dropout(p=0.5)(de_1)\n",
    "    #de_1 = merge([de_1, en_7], mode=merge_mode, concat_axis=1)\n",
    "    de_1 = concatenate([de_1, en_7],axis = bn_axis_1)\n",
    "    de_1 = Activation('relu')(de_1)\n",
    "\n",
    "    # 2 decoder CD1024 (decodes en_7)\n",
    "    de_2 = UpSampling2D(size=(2, 2))(de_1)\n",
    "    de_2 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_2)\n",
    "    de_2 = BatchNormalization(name='gen_de_bn_2', axis=bn_axis)(de_2)\n",
    "    de_2 = Dropout(p=0.5)(de_2)\n",
    "    #de_2 = merge([de_2, en_6], mode=merge_mode, concat_axis=1)\n",
    "    de_2 = concatenate([de_2, en_6],axis = bn_axis_1)\n",
    "    de_2 = Activation('relu')(de_2)\n",
    "\n",
    "    # 3 decoder CD1024 (decodes en_6)\n",
    "    de_3 = UpSampling2D(size=(2, 2))(de_2)\n",
    "    de_3 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_3)\n",
    "    de_3 = BatchNormalization(name='gen_de_bn_3', axis=bn_axis)(de_3)\n",
    "    de_3 = Dropout(p=0.5)(de_3)\n",
    "    #de_3 = merge([de_3, en_5], mode=merge_mode, concat_axis=1)\n",
    "    de_3 = concatenate([de_3, en_5],axis = bn_axis_1)\n",
    "    de_3 = Activation('relu')(de_3)\n",
    "\n",
    "    # 4 decoder CD1024 (decodes en_5)\n",
    "    de_4 = UpSampling2D(size=(2, 2))(de_3)\n",
    "    de_4 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_4)\n",
    "    de_4 = BatchNormalization(name='gen_de_bn_4', axis=bn_axis)(de_4)\n",
    "    de_4 = Dropout(p=0.5)(de_4)\n",
    "    #de_4 = merge([de_4, en_4], mode=merge_mode, concat_axis=1)\n",
    "    de_4 = concatenate([de_4, en_4],axis = bn_axis_1)\n",
    "    de_4 = Activation('relu')(de_4)\n",
    "\n",
    "    # 5 decoder CD1024 (decodes en_4)\n",
    "    de_5 = UpSampling2D(size=(2, 2))(de_4)\n",
    "    de_5 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_5)\n",
    "    de_5 = BatchNormalization(name='gen_de_bn_5', axis=bn_axis)(de_5)\n",
    "    de_5 = Dropout(p=0.5)(de_5)\n",
    "    #de_5 = merge([de_5, en_3], mode=merge_mode, concat_axis=1)\n",
    "    de_5 = concatenate([de_5, en_3],axis = bn_axis_1)\n",
    "    de_5 = Activation('relu')(de_5)\n",
    "\n",
    "    # 6 decoder C512 (decodes en_3)\n",
    "    de_6 = UpSampling2D(size=(2, 2))(de_5)\n",
    "    de_6 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same')(de_6)\n",
    "    de_6 = BatchNormalization(name='gen_de_bn_6', axis=bn_axis)(de_6)\n",
    "    de_6 = Dropout(p=0.5)(de_6)\n",
    "    #de_6 = merge([de_6, en_2], mode=merge_mode, concat_axis=1)\n",
    "    de_6 = concatenate([de_6, en_2],axis = bn_axis_1)\n",
    "    de_6 = Activation('relu')(de_6)\n",
    "\n",
    "    # 7 decoder CD256 (decodes en_2)\n",
    "    de_7 = UpSampling2D(size=(2, 2))(de_6)\n",
    "    de_7 = Convolution2D(nb_filter=256, nb_row=4, nb_col=4, border_mode='same')(de_7)\n",
    "    de_7 = BatchNormalization(name='gen_de_bn_7', axis=bn_axis)(de_7)\n",
    "    de_7 = Dropout(p=0.5)(de_7)\n",
    "    #de_7 = merge([de_7, en_1], mode=merge_mode, concat_axis=1)\n",
    "    de_7 = concatenate([de_7, en_1],axis = bn_axis_1)\n",
    "    de_7 = Activation('relu')(de_7)\n",
    "\n",
    "    # After the last layer in the decoder, a convolution is applied\n",
    "    # to map to the number of output channels (3 in general,\n",
    "    # except in colorization, where it is 2), followed by a Tanh\n",
    "    # function.\n",
    "    de_8 = UpSampling2D(size=(2, 2))(de_7)\n",
    "    de_8 = Convolution2D(nb_filter=num_output_channels, nb_row=4, nb_col=4, border_mode='same')(de_8)\n",
    "    # 最后一层在部分得layer得左上部分数值过大，导致拟合效果不好，加一个batchnorm试试\n",
    "    #de_8 = BatchNormalization(name='gen_de_bn_8', axis=bn_axis)(de_8)\n",
    "    de_8 = Activation('tanh')(de_8)\n",
    "\n",
    "    unet_generator = Model(input=[input_layer], output=[de_8], name='unet_generator')\n",
    "    return unet_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=256, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:105: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:121: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:123: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:132: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=3, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:156: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"unet_generator\", inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "generator_nn = UNETGenerator(input_img_dim=input_img_dim, num_output_channels=output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet_generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "unet_input (InputLayer)         (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 3136        unet_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   65600       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_2 (BatchNormalization (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 64)   0           gen_en_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 256)  262400      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_3 (BatchNormalization (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 256)  0           gen_en_bn_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_4 (BatchNormalization (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           gen_en_bn_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 512)    4194816     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_5 (BatchNormalization (None, 8, 8, 512)    2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 512)    0           gen_en_bn_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 512)    4194816     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_6 (BatchNormalization (None, 4, 4, 512)    2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 512)    0           gen_en_bn_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 2, 512)    4194816     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_7 (BatchNormalization (None, 2, 2, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 2, 2, 512)    0           gen_en_bn_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 512)    4194816     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_8 (BatchNormalization (None, 1, 1, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1, 1, 512)    0           gen_en_bn_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 2, 2, 512)    0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 2, 512)    4194816     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_1 (BatchNormalization (None, 2, 2, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 2, 512)    0           gen_de_bn_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 1024)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2, 2, 1024)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 4, 4, 1024)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 1024)   16778240    up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_2 (BatchNormalization (None, 4, 4, 1024)   4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 1024)   0           gen_de_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 1536)   0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4, 4, 1536)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 1536)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 1024)   25166848    up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_3 (BatchNormalization (None, 8, 8, 1024)   4096        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 1024)   0           gen_de_bn_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 1536)   0           dropout_3[0][0]                  \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 1536)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 1536) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 1024) 25166848    up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_4 (BatchNormalization (None, 16, 16, 1024) 4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 1024) 0           gen_de_bn_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1536) 0           dropout_4[0][0]                  \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 1536) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 1536) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 1024) 25166848    up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_5 (BatchNormalization (None, 32, 32, 1024) 4096        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 1024) 0           gen_de_bn_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 1280) 0           dropout_5[0][0]                  \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 1280) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 1280) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 512)  10486272    up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_6 (BatchNormalization (None, 64, 64, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 64, 512)  0           gen_de_bn_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 576)  0           dropout_6[0][0]                  \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 576)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 576 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 256 2359552     up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_7 (BatchNormalization (None, 128, 128, 256 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 128, 256 0           gen_de_bn_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 320 0           dropout_7[0][0]                  \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 320 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 320 0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 3)  15363       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256, 256, 3)  0           conv2d_16[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 128,575,875\n",
      "Trainable params: 128,559,363\n",
      "Non-trainable params: 16,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/1.jpg\")\n",
    "my_pic=  my_pic[:,256:,:]\n",
    "my_pic = my_pic.reshape(1,256,256,3)\n",
    "my_pic = (my_pic - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_weight(model,layer,my_pic):\n",
    "    print(generator_nn.layers[layer].name)\n",
    "    intermediate_layer_model = Model(inputs=model.input\n",
    "                                     ,outputs=model.layers[layer].output)\n",
    "    fake_pic = intermediate_layer_model.predict(my_pic)\n",
    "    fake_pic = fake_pic * 127.5 + 127.5\n",
    "    fake_pic = fake_pic.astype(np.uint8)\n",
    "    print(fake_pic.shape)\n",
    "    num = fake_pic.shape[-1]\n",
    "    plt.figure()\n",
    "    for i in range(1,min(25,num+1)):\n",
    "        #print(i)\n",
    "        plt.subplot(5,5,i)\n",
    "        plt.imshow(fake_pic[0][...,i-1])\n",
    "\n",
    "    #     plt.xticks([])\n",
    "    #     plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(model,layer,my_pic):\n",
    "    print(generator_nn.layers[layer].name,layer)\n",
    "    intermediate_layer_model = Model(inputs=model.input\n",
    "                                     ,outputs=model.layers[layer].output)\n",
    "    fake_pic = intermediate_layer_model.predict(my_pic)\n",
    "    #print(fake_pic.shape)\n",
    "    print(fake_pic[0,:10,:10,:].mean(0).mean(0)[:30])\n",
    "    print(fake_pic[0,-10:,-10:,:].mean(0).mean(0)[:30])\n",
    "    #print(fake_pic[0].mean(2))\n",
    "    print(\"*\"*20)\n",
    "    return fake_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt_discriminator = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#这把loss设置为mse加大对异常值的敏感度\n",
    "generator_nn.compile(loss='mae', optimizer=opt_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "ban_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/train/28.jpg\")\n",
    "my_pic = (my_pic - 127.5)/127.5\n",
    "my_pic_b=  my_pic[:,256:,:]\n",
    "my_pic_a=  my_pic[:,:256,:]\n",
    "my_pic_a = my_pic_a.reshape(1,256,256,3)\n",
    "my_pic_b = my_pic_b.reshape(1,256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_case = [1, 2, 4, 5, 6, 11, 12, 14, 22, 24, 25, 29, 35, 38, 39, 43, 44, 45, 47, 49, 51, 52, 54, 55, 56, 59, 63, 64, 76, 79, 82, 87, 92, 96, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 129, 132, 133, 134, 136, 141, 142, 143, 145, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 187, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 209, 214, 216, 217, 218, 223, 224, 225, 226, 230, 233, 237, 238, 241, 244, 246, 249, 253, 258, 259, 260, 261, 262, 264, 267, 268, 269, 273, 278, 279, 280, 281, 287, 292, 294, 295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘pic_fuck’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir pic_fuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 100 loss:0.17090296745300293\n",
      "epoch:0 101 loss:0.1711486577987671\n",
      "epoch:0 102 loss:0.17033830285072327\n",
      "epoch:0 103 loss:0.1691049039363861\n",
      "epoch:0 104 loss:0.16838137805461884\n",
      "epoch:0 105 loss:0.16884303092956543\n",
      "epoch:0 106 loss:0.1692100614309311\n",
      "epoch:0 107 loss:0.16828802227973938\n",
      "epoch:0 108 loss:0.16637739539146423\n",
      "epoch:0 109 loss:0.1677776575088501\n",
      "epoch:0 110 loss:0.16501496732234955\n",
      "epoch:0 111 loss:0.16474352777004242\n",
      "epoch:0 112 loss:0.16503986716270447\n",
      "epoch:0 113 loss:0.165230393409729\n",
      "epoch:0 114 loss:0.1638486385345459\n",
      "epoch:0 115 loss:0.16370289027690887\n",
      "epoch:0 116 loss:0.16269466280937195\n",
      "epoch:0 117 loss:0.1619585156440735\n",
      "epoch:0 118 loss:0.1613035500049591\n",
      "epoch:0 119 loss:0.16316251456737518\n",
      "epoch:0 120 loss:0.16128239035606384\n",
      "epoch:0 121 loss:0.15965795516967773\n",
      "epoch:0 122 loss:0.16200003027915955\n",
      "epoch:0 123 loss:0.159181147813797\n",
      "epoch:0 124 loss:0.1601162552833557\n",
      "epoch:0 125 loss:0.16024552285671234\n",
      "epoch:0 126 loss:0.15847468376159668\n",
      "epoch:0 127 loss:0.16137200593948364\n",
      "epoch:0 128 loss:0.15712250769138336\n",
      "epoch:0 129 loss:0.15837833285331726\n",
      "epoch:0 130 loss:0.15609583258628845\n",
      "epoch:0 131 loss:0.15581291913986206\n",
      "epoch:0 132 loss:0.15517622232437134\n",
      "epoch:0 133 loss:0.15803053975105286\n",
      "epoch:0 134 loss:0.15415748953819275\n",
      "epoch:0 135 loss:0.15440596640110016\n",
      "epoch:0 136 loss:0.15566036105155945\n",
      "epoch:0 137 loss:0.1543537825345993\n",
      "epoch:0 138 loss:0.1537117063999176\n",
      "epoch:0 139 loss:0.15398837625980377\n",
      "epoch:0 140 loss:0.15567108988761902\n",
      "epoch:0 141 loss:0.15601320564746857\n",
      "epoch:0 142 loss:0.1564749777317047\n",
      "epoch:0 143 loss:0.15170875191688538\n",
      "epoch:0 144 loss:0.15606769919395447\n",
      "epoch:0 145 loss:0.15415039658546448\n",
      "epoch:0 146 loss:0.14997872710227966\n",
      "epoch:0 147 loss:0.1567789912223816\n",
      "epoch:0 148 loss:0.15217722952365875\n",
      "epoch:0 149 loss:0.15032389760017395\n",
      "epoch:0 150 loss:0.15111815929412842\n",
      "epoch:0 151 loss:0.15464185178279877\n",
      "epoch:0 152 loss:0.1494188904762268\n",
      "epoch:0 153 loss:0.1530981957912445\n",
      "epoch:0 154 loss:0.15286514163017273\n",
      "epoch:0 155 loss:0.15049625933170319\n",
      "epoch:0 156 loss:0.1484132707118988\n",
      "epoch:0 157 loss:0.1506761610507965\n",
      "epoch:0 158 loss:0.1487797498703003\n",
      "epoch:0 159 loss:0.1472320556640625\n",
      "epoch:0 160 loss:0.14659661054611206\n",
      "epoch:0 161 loss:0.14617010951042175\n",
      "epoch:0 162 loss:0.14653801918029785\n",
      "epoch:0 163 loss:0.1444149911403656\n",
      "epoch:0 164 loss:0.1438031792640686\n",
      "epoch:0 165 loss:0.14440397918224335\n",
      "epoch:0 166 loss:0.14421962201595306\n",
      "epoch:0 167 loss:0.1427266001701355\n",
      "epoch:0 168 loss:0.14267893135547638\n",
      "epoch:0 169 loss:0.14252632856369019\n",
      "epoch:0 170 loss:0.14300352334976196\n",
      "epoch:0 171 loss:0.14320959150791168\n",
      "epoch:0 172 loss:0.14273768663406372\n",
      "epoch:0 173 loss:0.14162230491638184\n",
      "epoch:0 174 loss:0.14091211557388306\n",
      "epoch:0 175 loss:0.1413852572441101\n",
      "epoch:0 176 loss:0.1405515968799591\n",
      "epoch:0 177 loss:0.14267288148403168\n",
      "epoch:0 178 loss:0.14307770133018494\n",
      "epoch:0 179 loss:0.1423347294330597\n",
      "epoch:0 180 loss:0.14203421771526337\n",
      "epoch:0 181 loss:0.1420258730649948\n",
      "epoch:0 182 loss:0.14169824123382568\n",
      "epoch:0 183 loss:0.14521479606628418\n",
      "epoch:0 184 loss:0.14013510942459106\n",
      "epoch:0 185 loss:0.1432398408651352\n",
      "epoch:0 186 loss:0.14195962250232697\n",
      "epoch:0 187 loss:0.1399563103914261\n",
      "epoch:0 188 loss:0.14210687577724457\n",
      "epoch:0 189 loss:0.14410695433616638\n",
      "epoch:0 190 loss:0.13891468942165375\n",
      "epoch:0 191 loss:0.14528070390224457\n",
      "epoch:0 192 loss:0.14001509547233582\n",
      "epoch:0 193 loss:0.13794837892055511\n",
      "epoch:0 194 loss:0.13836833834648132\n",
      "epoch:0 195 loss:0.13893811404705048\n",
      "epoch:0 196 loss:0.1366281807422638\n",
      "epoch:0 197 loss:0.13656026124954224\n",
      "epoch:0 198 loss:0.13801205158233643\n",
      "epoch:0 199 loss:0.13834747672080994\n",
      "epoch:0 200 loss:0.13538378477096558\n",
      "epoch:0 201 loss:0.1404804289340973\n",
      "epoch:0 202 loss:0.13524293899536133\n",
      "epoch:0 203 loss:0.13439446687698364\n",
      "epoch:0 204 loss:0.13802075386047363\n",
      "epoch:0 205 loss:0.13602030277252197\n",
      "epoch:0 206 loss:0.1337309628725052\n",
      "epoch:0 207 loss:0.1335456669330597\n",
      "epoch:0 208 loss:0.1341312825679779\n",
      "epoch:0 209 loss:0.13378480076789856\n",
      "epoch:0 210 loss:0.13310328125953674\n",
      "epoch:0 211 loss:0.13390396535396576\n",
      "epoch:0 212 loss:0.13264328241348267\n",
      "epoch:0 213 loss:0.1320551335811615\n",
      "epoch:0 214 loss:0.1320551633834839\n",
      "epoch:0 215 loss:0.13249799609184265\n",
      "epoch:0 216 loss:0.13078980147838593\n",
      "epoch:0 217 loss:0.13079805672168732\n",
      "epoch:0 218 loss:0.13191114366054535\n",
      "epoch:0 219 loss:0.13128522038459778\n",
      "epoch:0 220 loss:0.1311628371477127\n",
      "epoch:0 221 loss:0.13155622780323029\n",
      "epoch:0 222 loss:0.1315639615058899\n",
      "epoch:0 223 loss:0.12953490018844604\n",
      "epoch:0 224 loss:0.13025137782096863\n",
      "epoch:0 225 loss:0.12882128357887268\n",
      "epoch:0 226 loss:0.12928162515163422\n",
      "epoch:0 227 loss:0.13159126043319702\n",
      "epoch:0 228 loss:0.12905120849609375\n",
      "epoch:0 229 loss:0.13001805543899536\n",
      "epoch:0 230 loss:0.12814900279045105\n",
      "epoch:0 231 loss:0.12841731309890747\n",
      "epoch:0 232 loss:0.1278517246246338\n",
      "epoch:0 233 loss:0.1273694634437561\n",
      "epoch:0 234 loss:0.12761333584785461\n",
      "epoch:0 235 loss:0.12767758965492249\n",
      "epoch:0 236 loss:0.12772470712661743\n",
      "epoch:0 237 loss:0.12956859171390533\n",
      "epoch:0 238 loss:0.126909077167511\n",
      "epoch:0 239 loss:0.12703382968902588\n",
      "epoch:0 240 loss:0.1265178620815277\n",
      "epoch:0 241 loss:0.12575936317443848\n",
      "epoch:0 242 loss:0.12618674337863922\n",
      "epoch:0 243 loss:0.12545953691005707\n",
      "epoch:0 244 loss:0.1252424120903015\n",
      "epoch:0 245 loss:0.12558576464653015\n",
      "epoch:0 246 loss:0.12350931763648987\n",
      "epoch:0 247 loss:0.12475451827049255\n",
      "epoch:0 248 loss:0.1243378072977066\n",
      "epoch:0 249 loss:0.12684616446495056\n",
      "epoch:0 250 loss:0.12308043241500854\n",
      "epoch:0 251 loss:0.12604065239429474\n",
      "epoch:0 252 loss:0.12460705637931824\n",
      "epoch:0 253 loss:0.1257876753807068\n",
      "epoch:0 254 loss:0.12514010071754456\n",
      "epoch:0 255 loss:0.12337047606706619\n",
      "epoch:0 256 loss:0.12546400725841522\n",
      "epoch:0 257 loss:0.12309122085571289\n",
      "epoch:0 258 loss:0.12194965779781342\n",
      "epoch:0 259 loss:0.12233570218086243\n",
      "epoch:0 260 loss:0.1225595474243164\n",
      "epoch:0 261 loss:0.1219039186835289\n",
      "epoch:0 262 loss:0.12181360274553299\n",
      "epoch:0 263 loss:0.12176644802093506\n",
      "epoch:0 264 loss:0.12331295013427734\n",
      "epoch:0 265 loss:0.12087994813919067\n",
      "epoch:0 266 loss:0.1237604171037674\n",
      "epoch:0 267 loss:0.1216062605381012\n",
      "epoch:0 268 loss:0.12340319901704788\n",
      "epoch:0 269 loss:0.12309642881155014\n",
      "epoch:0 270 loss:0.12055175751447678\n",
      "epoch:0 271 loss:0.1235341727733612\n",
      "epoch:0 272 loss:0.12061633169651031\n",
      "epoch:0 273 loss:0.1201208233833313\n",
      "epoch:0 274 loss:0.1197434514760971\n",
      "epoch:0 275 loss:0.11991892755031586\n",
      "epoch:0 276 loss:0.1197199672460556\n",
      "epoch:0 277 loss:0.11997145414352417\n",
      "epoch:0 278 loss:0.12079079449176788\n",
      "epoch:0 279 loss:0.12176983803510666\n",
      "epoch:0 280 loss:0.12224170565605164\n",
      "epoch:0 281 loss:0.1187908872961998\n",
      "epoch:0 282 loss:0.11940345168113708\n",
      "epoch:0 283 loss:0.11791308969259262\n",
      "epoch:0 284 loss:0.11835385859012604\n",
      "epoch:0 285 loss:0.11865164339542389\n",
      "epoch:0 286 loss:0.1211131364107132\n",
      "epoch:0 287 loss:0.11720298230648041\n",
      "epoch:0 288 loss:0.11719819903373718\n",
      "epoch:0 289 loss:0.11829400062561035\n",
      "epoch:0 290 loss:0.11884752660989761\n",
      "epoch:0 291 loss:0.11762979626655579\n",
      "epoch:0 292 loss:0.11890290677547455\n",
      "epoch:0 293 loss:0.11745394766330719\n",
      "epoch:0 294 loss:0.11810439825057983\n",
      "epoch:0 295 loss:0.11865296959877014\n",
      "epoch:0 296 loss:0.11663304269313812\n",
      "epoch:0 297 loss:0.11568821221590042\n",
      "epoch:0 298 loss:0.11697188019752502\n",
      "epoch:0 299 loss:0.11604969948530197\n"
     ]
    }
   ],
   "source": [
    "disc_loss =0\n",
    "epoch=0\n",
    "for j in range(100,300):\n",
    "#for i in bad_case: \n",
    "    i = 124\n",
    "    disc_loss_cur =  generator_nn.train_on_batch(my_pic_b,my_pic_a)\n",
    "    disc_loss += disc_loss_cur\n",
    "    output_pic =  generator_nn.predict(my_pic_b)\n",
    "    fake_pic = generator_nn.predict(my_pic_b)\n",
    "    fake_pic = np.concatenate((fake_pic,output_pic,my_pic_a),1)\n",
    "    fake_pic = fake_pic * 127.5 + 127.5\n",
    "    cv2.imwrite(\"./pic_fuck/result_{}.jpg\".format(j),fake_pic[0])\n",
    "    print(\"epoch:{} {} loss:{}\".format(epoch,j,disc_loss_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator_nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-b75b7c821997>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#for i in bad_case:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m124\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdisc_loss_cur\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgenerator_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_iamge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0morigin_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mdisc_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdisc_loss_cur\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0moutput_pic\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mgenerator_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_iamge\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator_nn' is not defined"
     ]
    }
   ],
   "source": [
    "for j in range(0,100):\n",
    "#for i in bad_case: \n",
    "    i = 124\n",
    "    disc_loss_cur =  generator_nn.train_on_batch(true_iamge[i:i+1],origin_image[i:i+1])\n",
    "    disc_loss += disc_loss_cur\n",
    "    output_pic =  generator_nn.predict(true_iamge[i:i+1])\n",
    "    fake_pic = generator_nn.predict(my_pic)\n",
    "    fake_pic = np.concatenate((fake_pic,output_pic,origin_image[i:i+1]),1)\n",
    "    fake_pic = fake_pic * 127.5 + 127.5\n",
    "    cv2.imwrite(\"./pic_fuck_191/result_{}.jpg\".format(j),fake_pic[0])\n",
    "    print(\"epoch:{} {} loss:{}\".format(epoch,j,disc_loss_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/4.jpg\")\n",
    "my_pic=  my_pic[:,256:,:]\n",
    "my_pic = my_pic.reshape(1,256,256,3)\n",
    "my_pic = (my_pic - 127.5) / 127.5\n",
    "fake_pic = generator_nn.predict(my_pic)\n",
    "fake_pic = fake_pic * 127.5 + 127.5\n",
    "cv2.imwrite(\"result.jpg\".format(epoch),fake_pic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/49.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSV = cv2.cvtColor(my_pic, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
