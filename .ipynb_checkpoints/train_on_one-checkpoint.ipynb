{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#from generator import UNETGenerator\n",
    "from keras.layers import Activation, Input, Dropout, merge,concatenate\n",
    "from keras.layers.convolutional import Convolution2D, UpSampling2D\n",
    "from keras.layers import Conv2D,Conv2DTranspose\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# HYPER PARAMS\n",
    "# ---------------------------------------------\n",
    "# width, height of images to work with. Assumes images are square\n",
    "im_width = im_height = 256\n",
    "\n",
    "# inpu/oputputt channels in image\n",
    "input_channels = 3\n",
    "output_channels = 3\n",
    "\n",
    "# image dims\n",
    "input_img_dim = (im_width, im_height,input_channels)\n",
    "output_img_dim = (im_width, im_height,output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNETGenerator(input_img_dim, num_output_channels):\n",
    "    \"\"\"\n",
    "    Creates the generator according to the specs in the paper below.\n",
    "    It's basically a skip layer AutoEncoder\n",
    "    Generator does the following:\n",
    "    1. Takes in an image\n",
    "    2. Generates an image from this image\n",
    "    Differs from a standard GAN because the image isn't random.\n",
    "    This model tries to learn a mapping from a suboptimal image to an optimal image.\n",
    "    [https://arxiv.org/pdf/1611.07004v1.pdf][5. Appendix]\n",
    "    :param input_img_dim: (channel, height, width)\n",
    "    :param output_img_dim: (channel, height, width)\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # -------------------------------\n",
    "    # ENCODER\n",
    "    # C64-C128-C256-C512-C512-C512-C512-C512\n",
    "    # 1 layer block = Conv - BN - LeakyRelu\n",
    "    # -------------------------------\n",
    "    stride = 2\n",
    "    merge_mode = 'concat'\n",
    "\n",
    "    # batch norm mode\n",
    "    bn_mode = 2\n",
    "\n",
    "    # batch norm merge axis\n",
    "    bn_axis = 3\n",
    "    bn_axis_1 = 3\n",
    "\n",
    "    input_layer = Input(shape=input_img_dim, name=\"unet_input\")\n",
    "\n",
    "    # 1 encoder C64\n",
    "    # skip batchnorm on this layer on purpose (from paper)\n",
    "    en_1 = Convolution2D(nb_filter=64, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(input_layer)\n",
    "    #en_1 = Conv2D(filters=64,kernel_size=4,padding=\"same\",strides=2)(input_layer)\n",
    "    en_1 = LeakyReLU(alpha=0.2)(en_1)\n",
    "\n",
    "#     # 2 encoder C128\n",
    "    en_2 = Convolution2D(nb_filter=64, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_1)\n",
    "    #en_2 = Conv2D(filters=64,kernel_size=4,padding=\"same\",strides=2)(en_1)\n",
    "    en_2 = BatchNormalization(name='gen_en_bn_2', axis=bn_axis)(en_2)\n",
    "    en_2 = LeakyReLU(alpha=0.2)(en_2)\n",
    "\n",
    "    # 3 encoder C256\n",
    "    en_3 = Convolution2D(nb_filter=256, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_2)\n",
    "    en_3 = BatchNormalization(name='gen_en_bn_3', axis=bn_axis)(en_3)\n",
    "    en_3 = LeakyReLU(alpha=0.2)(en_3)\n",
    "\n",
    "    # 4 encoder C512\n",
    "    en_4 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_3)\n",
    "    en_4 = BatchNormalization(name='gen_en_bn_4', axis=bn_axis)(en_4)\n",
    "    en_4 = LeakyReLU(alpha=0.2)(en_4)\n",
    "\n",
    "    # 5 encoder C512\n",
    "    en_5 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_4)\n",
    "    en_5 = BatchNormalization(name='gen_en_bn_5', axis=bn_axis)(en_5)\n",
    "    en_5 = LeakyReLU(alpha=0.2)(en_5)\n",
    "\n",
    "    # 6 encoder C512\n",
    "    en_6 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_5)\n",
    "    en_6 = BatchNormalization(name='gen_en_bn_6', axis=bn_axis)(en_6)\n",
    "    en_6 = LeakyReLU(alpha=0.2)(en_6)\n",
    "\n",
    "    # 7 encoder C512\n",
    "    en_7 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_6)\n",
    "    en_7 = BatchNormalization(name='gen_en_bn_7', axis=bn_axis)(en_7)\n",
    "    en_7 = LeakyReLU(alpha=0.2)(en_7)\n",
    "\n",
    "    # 8 encoder C512\n",
    "    en_8 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same', subsample=(stride, stride))(en_7)\n",
    "    en_8 = BatchNormalization(name='gen_en_bn_8', axis=bn_axis)(en_8)\n",
    "    en_8 = LeakyReLU(alpha=0.2)(en_8)\n",
    "    \n",
    "#    unet_generator = Model(input=[input_layer], output=[en_8], name='unet_generator')\n",
    "\n",
    "\n",
    "    # -------------------------------\n",
    "    # DECODER\n",
    "    # CD512-CD1024-CD1024-C1024-C1024-C512-C256-C128\n",
    "    # 1 layer block = Conv - Upsample - BN - DO - Relu\n",
    "    # also adds skip connections (merge). Takes input from previous layer matching encoder layer\n",
    "    # -------------------------------\n",
    "    # 1 decoder CD512 (decodes en_8)\n",
    "    de_1 = UpSampling2D(size=(2, 2))(en_8)\n",
    "    de_1 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same')(de_1)\n",
    "    de_1 = BatchNormalization(name='gen_de_bn_1', axis=bn_axis)(de_1)\n",
    "    de_1 = Dropout(p=0.5)(de_1)\n",
    "    #de_1 = merge([de_1, en_7], mode=merge_mode, concat_axis=1)\n",
    "    de_1 = concatenate([de_1, en_7],axis = bn_axis_1)\n",
    "    de_1 = Activation('relu')(de_1)\n",
    "\n",
    "    # 2 decoder CD1024 (decodes en_7)\n",
    "    de_2 = UpSampling2D(size=(2, 2))(de_1)\n",
    "    de_2 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_2)\n",
    "    de_2 = BatchNormalization(name='gen_de_bn_2', axis=bn_axis)(de_2)\n",
    "    de_2 = Dropout(p=0.5)(de_2)\n",
    "    #de_2 = merge([de_2, en_6], mode=merge_mode, concat_axis=1)\n",
    "    de_2 = concatenate([de_2, en_6],axis = bn_axis_1)\n",
    "    de_2 = Activation('relu')(de_2)\n",
    "\n",
    "    # 3 decoder CD1024 (decodes en_6)\n",
    "    de_3 = UpSampling2D(size=(2, 2))(de_2)\n",
    "    de_3 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_3)\n",
    "    de_3 = BatchNormalization(name='gen_de_bn_3', axis=bn_axis)(de_3)\n",
    "    de_3 = Dropout(p=0.5)(de_3)\n",
    "    #de_3 = merge([de_3, en_5], mode=merge_mode, concat_axis=1)\n",
    "    de_3 = concatenate([de_3, en_5],axis = bn_axis_1)\n",
    "    de_3 = Activation('relu')(de_3)\n",
    "\n",
    "    # 4 decoder CD1024 (decodes en_5)\n",
    "    de_4 = UpSampling2D(size=(2, 2))(de_3)\n",
    "    de_4 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_4)\n",
    "    de_4 = BatchNormalization(name='gen_de_bn_4', axis=bn_axis)(de_4)\n",
    "    de_4 = Dropout(p=0.5)(de_4)\n",
    "    #de_4 = merge([de_4, en_4], mode=merge_mode, concat_axis=1)\n",
    "    de_4 = concatenate([de_4, en_4],axis = bn_axis_1)\n",
    "    de_4 = Activation('relu')(de_4)\n",
    "\n",
    "    # 5 decoder CD1024 (decodes en_4)\n",
    "    de_5 = UpSampling2D(size=(2, 2))(de_4)\n",
    "    de_5 = Convolution2D(nb_filter=1024, nb_row=4, nb_col=4, border_mode='same')(de_5)\n",
    "    de_5 = BatchNormalization(name='gen_de_bn_5', axis=bn_axis)(de_5)\n",
    "    de_5 = Dropout(p=0.5)(de_5)\n",
    "    #de_5 = merge([de_5, en_3], mode=merge_mode, concat_axis=1)\n",
    "    de_5 = concatenate([de_5, en_3],axis = bn_axis_1)\n",
    "    de_5 = Activation('relu')(de_5)\n",
    "\n",
    "    # 6 decoder C512 (decodes en_3)\n",
    "    de_6 = UpSampling2D(size=(2, 2))(de_5)\n",
    "    de_6 = Convolution2D(nb_filter=512, nb_row=4, nb_col=4, border_mode='same')(de_6)\n",
    "    de_6 = BatchNormalization(name='gen_de_bn_6', axis=bn_axis)(de_6)\n",
    "    de_6 = Dropout(p=0.5)(de_6)\n",
    "    #de_6 = merge([de_6, en_2], mode=merge_mode, concat_axis=1)\n",
    "    de_6 = concatenate([de_6, en_2],axis = bn_axis_1)\n",
    "    de_6 = Activation('relu')(de_6)\n",
    "\n",
    "    # 7 decoder CD256 (decodes en_2)\n",
    "    de_7 = UpSampling2D(size=(2, 2))(de_6)\n",
    "    de_7 = Convolution2D(nb_filter=256, nb_row=4, nb_col=4, border_mode='same')(de_7)\n",
    "    de_7 = BatchNormalization(name='gen_de_bn_7', axis=bn_axis)(de_7)\n",
    "    de_7 = Dropout(p=0.5)(de_7)\n",
    "    #de_7 = merge([de_7, en_1], mode=merge_mode, concat_axis=1)\n",
    "    de_7 = concatenate([de_7, en_1],axis = bn_axis_1)\n",
    "    de_7 = Activation('relu')(de_7)\n",
    "\n",
    "    # After the last layer in the decoder, a convolution is applied\n",
    "    # to map to the number of output channels (3 in general,\n",
    "    # except in colorization, where it is 2), followed by a Tanh\n",
    "    # function.\n",
    "    de_8 = UpSampling2D(size=(2, 2))(de_7)\n",
    "    de_8 = Convolution2D(nb_filter=num_output_channels, nb_row=4, nb_col=4, border_mode='same')(de_8)\n",
    "    # 最后一层在部分得layer得左上部分数值过大，导致拟合效果不好，加一个batchnorm试试\n",
    "    #de_8 = BatchNormalization(name='gen_de_bn_8', axis=bn_axis)(de_8)\n",
    "    de_8 = Activation('tanh')(de_8)\n",
    "\n",
    "    unet_generator = Model(input=[input_layer], output=[de_8], name='unet_generator')\n",
    "    return unet_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:34: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=64, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:45: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=256, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:50: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:65: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:70: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, strides=(2, 2), padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:85: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:96: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:103: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:105: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:112: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:114: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:121: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=1024, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:123: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:130: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=512, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:132: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:139: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=256, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:141: UserWarning: Update your `Dropout` call to the Keras 2 API: `Dropout(rate=0.5)`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:151: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(4, 4), filters=3, padding=\"same\")`\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:156: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"unet_generator\", inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "generator_nn = UNETGenerator(input_img_dim=input_img_dim, num_output_channels=output_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"unet_generator\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "unet_input (InputLayer)         (None, 256, 256, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 128, 128, 64) 3136        unet_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 128, 128, 64) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 64, 64, 64)   65600       leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_2 (BatchNormalization (None, 64, 64, 64)   256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 64, 64, 64)   0           gen_en_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 32, 32, 256)  262400      leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_3 (BatchNormalization (None, 32, 32, 256)  1024        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32, 32, 256)  0           gen_en_bn_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 16, 16, 512)  2097664     leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_4 (BatchNormalization (None, 16, 16, 512)  2048        conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 16, 16, 512)  0           gen_en_bn_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 8, 8, 512)    4194816     leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_5 (BatchNormalization (None, 8, 8, 512)    2048        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 8, 8, 512)    0           gen_en_bn_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 4, 4, 512)    4194816     leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_6 (BatchNormalization (None, 4, 4, 512)    2048        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 4, 4, 512)    0           gen_en_bn_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 2, 2, 512)    4194816     leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_7 (BatchNormalization (None, 2, 2, 512)    2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)       (None, 2, 2, 512)    0           gen_en_bn_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 1, 1, 512)    4194816     leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gen_en_bn_8 (BatchNormalization (None, 1, 1, 512)    2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)       (None, 1, 1, 512)    0           gen_en_bn_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 2, 2, 512)    0           leaky_re_lu_8[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 2, 2, 512)    4194816     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_1 (BatchNormalization (None, 2, 2, 512)    2048        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2, 2, 512)    0           gen_de_bn_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 1024)   0           dropout_1[0][0]                  \n",
      "                                                                 leaky_re_lu_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 2, 2, 1024)   0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 4, 4, 1024)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 4, 4, 1024)   16778240    up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_2 (BatchNormalization (None, 4, 4, 1024)   4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 4, 4, 1024)   0           gen_de_bn_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 4, 4, 1536)   0           dropout_2[0][0]                  \n",
      "                                                                 leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 4, 4, 1536)   0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 8, 8, 1536)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 8, 8, 1024)   25166848    up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_3 (BatchNormalization (None, 8, 8, 1024)   4096        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 8, 8, 1024)   0           gen_de_bn_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 8, 8, 1536)   0           dropout_3[0][0]                  \n",
      "                                                                 leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 8, 8, 1536)   0           concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 16, 16, 1536) 0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 16, 16, 1024) 25166848    up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_4 (BatchNormalization (None, 16, 16, 1024) 4096        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 16, 16, 1024) 0           gen_de_bn_4[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 16, 16, 1536) 0           dropout_4[0][0]                  \n",
      "                                                                 leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 16, 16, 1536) 0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2D)  (None, 32, 32, 1536) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 32, 32, 1024) 25166848    up_sampling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_5 (BatchNormalization (None, 32, 32, 1024) 4096        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 32, 32, 1024) 0           gen_de_bn_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 32, 32, 1280) 0           dropout_5[0][0]                  \n",
      "                                                                 leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 32, 32, 1280) 0           concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2D)  (None, 64, 64, 1280) 0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 64, 64, 512)  10486272    up_sampling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_6 (BatchNormalization (None, 64, 64, 512)  2048        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64, 64, 512)  0           gen_de_bn_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 64, 64, 576)  0           dropout_6[0][0]                  \n",
      "                                                                 leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 64, 64, 576)  0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2D)  (None, 128, 128, 576 0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 256 2359552     up_sampling2d_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "gen_de_bn_7 (BatchNormalization (None, 128, 128, 256 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 128, 128, 256 0           gen_de_bn_7[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 128, 128, 320 0           dropout_7[0][0]                  \n",
      "                                                                 leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 128, 128, 320 0           concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2D)  (None, 256, 256, 320 0           activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 256, 256, 3)  15363       up_sampling2d_8[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 256, 256, 3)  0           conv2d_16[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 128,575,875\n",
      "Trainable params: 128,559,363\n",
      "Non-trainable params: 16,512\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator_nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/1.jpg\")\n",
    "my_pic=  my_pic[:,256:,:]\n",
    "my_pic = my_pic.reshape(1,256,256,3)\n",
    "my_pic = (my_pic - 127.5) / 127.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_weight(model,layer,my_pic):\n",
    "    print(generator_nn.layers[layer].name)\n",
    "    intermediate_layer_model = Model(inputs=model.input\n",
    "                                     ,outputs=model.layers[layer].output)\n",
    "    fake_pic = intermediate_layer_model.predict(my_pic)\n",
    "    fake_pic = fake_pic * 127.5 + 127.5\n",
    "    fake_pic = fake_pic.astype(np.uint8)\n",
    "    print(fake_pic.shape)\n",
    "    num = fake_pic.shape[-1]\n",
    "    plt.figure()\n",
    "    for i in range(1,min(25,num+1)):\n",
    "        #print(i)\n",
    "        plt.subplot(5,5,i)\n",
    "        plt.imshow(fake_pic[0][...,i-1])\n",
    "\n",
    "    #     plt.xticks([])\n",
    "    #     plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weight(model,layer,my_pic):\n",
    "    print(generator_nn.layers[layer].name,layer)\n",
    "    intermediate_layer_model = Model(inputs=model.input\n",
    "                                     ,outputs=model.layers[layer].output)\n",
    "    fake_pic = intermediate_layer_model.predict(my_pic)\n",
    "    #print(fake_pic.shape)\n",
    "    print(fake_pic[0,:10,:10,:].mean(0).mean(0)[:30])\n",
    "    print(fake_pic[0,-10:,-10:,:].mean(0).mean(0)[:30])\n",
    "    #print(fake_pic[0].mean(2))\n",
    "    print(\"*\"*20)\n",
    "    return fake_pic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "opt_discriminator = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "#这把loss设置为mse加大对异常值的敏感度\n",
    "generator_nn.compile(loss='mae', optimizer=opt_discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pickle\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "ban_num = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/train/28.jpg\")\n",
    "my_pic = (my_pic - 127.5)/127.5\n",
    "my_pic_b=  my_pic[:,256:,:]\n",
    "my_pic_a=  my_pic[:,:256,:]\n",
    "my_pic_a = my_pic_a.reshape(1,256,256,3)\n",
    "my_pic_b = my_pic_b.reshape(1,256,256,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_case = [1, 2, 4, 5, 6, 11, 12, 14, 22, 24, 25, 29, 35, 38, 39, 43, 44, 45, 47, 49, 51, 52, 54, 55, 56, 59, 63, 64, 76, 79, 82, 87, 92, 96, 98, 100, 102, 103, 104, 106, 108, 109, 110, 111, 115, 116, 117, 118, 119, 120, 123, 124, 125, 126, 127, 129, 132, 133, 134, 136, 141, 142, 143, 145, 149, 150, 151, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 166, 167, 168, 169, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 187, 189, 190, 191, 193, 194, 195, 196, 197, 198, 199, 200, 209, 214, 216, 217, 218, 223, 224, 225, 226, 230, 233, 237, 238, 241, 244, 246, 249, 253, 258, 259, 260, 261, 262, 264, 267, 268, 269, 273, 278, 279, 280, 281, 287, 292, 294, 295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘pic_fuck’: File exists\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir pic_fuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 0 loss:0.10862031579017639\n",
      "epoch:0 1 loss:0.10443038493394852\n",
      "epoch:0 2 loss:0.10475747287273407\n",
      "epoch:0 3 loss:0.10519291460514069\n",
      "epoch:0 4 loss:0.1046702116727829\n",
      "epoch:0 5 loss:0.10402727127075195\n",
      "epoch:0 6 loss:0.1043660119175911\n",
      "epoch:0 7 loss:0.10454048216342926\n",
      "epoch:0 8 loss:0.10574880242347717\n",
      "epoch:0 9 loss:0.10663251578807831\n",
      "epoch:0 10 loss:0.10444097220897675\n",
      "epoch:0 11 loss:0.10369522124528885\n",
      "epoch:0 12 loss:0.11080329865217209\n",
      "epoch:0 13 loss:0.11198018491268158\n",
      "epoch:0 14 loss:0.1028960645198822\n",
      "epoch:0 15 loss:0.10614655911922455\n",
      "epoch:0 16 loss:0.11593331396579742\n",
      "epoch:0 17 loss:0.11119244992733002\n",
      "epoch:0 18 loss:0.104220911860466\n",
      "epoch:0 19 loss:0.1119784265756607\n",
      "epoch:0 20 loss:0.11213941872119904\n",
      "epoch:0 21 loss:0.11195872724056244\n",
      "epoch:0 22 loss:0.10636214166879654\n",
      "epoch:0 23 loss:0.10606062412261963\n",
      "epoch:0 24 loss:0.1065794974565506\n",
      "epoch:0 25 loss:0.10847664624452591\n",
      "epoch:0 26 loss:0.1064923107624054\n",
      "epoch:0 27 loss:0.10426466166973114\n",
      "epoch:0 28 loss:0.10472219437360764\n",
      "epoch:0 29 loss:0.11401757597923279\n",
      "epoch:0 30 loss:0.1075328141450882\n",
      "epoch:0 31 loss:0.10331311821937561\n",
      "epoch:0 32 loss:0.10134437680244446\n",
      "epoch:0 33 loss:0.10436613112688065\n",
      "epoch:0 34 loss:0.1069812923669815\n",
      "epoch:0 35 loss:0.10482341051101685\n",
      "epoch:0 36 loss:0.10141646862030029\n",
      "epoch:0 37 loss:0.10295465588569641\n",
      "epoch:0 38 loss:0.10304006934165955\n",
      "epoch:0 39 loss:0.10577718913555145\n",
      "epoch:0 40 loss:0.10384191572666168\n",
      "epoch:0 41 loss:0.10302990674972534\n",
      "epoch:0 42 loss:0.10502217710018158\n",
      "epoch:0 43 loss:0.10598976165056229\n",
      "epoch:0 44 loss:0.10240082442760468\n",
      "epoch:0 45 loss:0.10114855319261551\n",
      "epoch:0 46 loss:0.1101636216044426\n",
      "epoch:0 47 loss:0.1102711409330368\n",
      "epoch:0 48 loss:0.10276159644126892\n",
      "epoch:0 49 loss:0.1043679490685463\n",
      "epoch:0 50 loss:0.10638193786144257\n",
      "epoch:0 51 loss:0.103228360414505\n",
      "epoch:0 52 loss:0.10365240275859833\n",
      "epoch:0 53 loss:0.10302683711051941\n",
      "epoch:0 54 loss:0.10281854122877121\n",
      "epoch:0 55 loss:0.10287801176309586\n",
      "epoch:0 56 loss:0.10448001325130463\n",
      "epoch:0 57 loss:0.10275140404701233\n",
      "epoch:0 58 loss:0.10030028969049454\n",
      "epoch:0 59 loss:0.10149624198675156\n",
      "epoch:0 60 loss:0.10222916305065155\n",
      "epoch:0 61 loss:0.101052425801754\n",
      "epoch:0 62 loss:0.0999847799539566\n",
      "epoch:0 63 loss:0.10033975541591644\n",
      "epoch:0 64 loss:0.10066748410463333\n",
      "epoch:0 65 loss:0.09883495420217514\n",
      "epoch:0 66 loss:0.09935367107391357\n",
      "epoch:0 67 loss:0.09948787093162537\n",
      "epoch:0 68 loss:0.09894700348377228\n",
      "epoch:0 69 loss:0.10007058084011078\n",
      "epoch:0 70 loss:0.09935085475444794\n",
      "epoch:0 71 loss:0.09894084930419922\n",
      "epoch:0 72 loss:0.09713002294301987\n",
      "epoch:0 73 loss:0.10010027885437012\n",
      "epoch:0 74 loss:0.10095640271902084\n",
      "epoch:0 75 loss:0.10021118819713593\n",
      "epoch:0 76 loss:0.09732796251773834\n",
      "epoch:0 77 loss:0.09900988638401031\n",
      "epoch:0 78 loss:0.10160332918167114\n",
      "epoch:0 79 loss:0.10138490796089172\n",
      "epoch:0 80 loss:0.09725818783044815\n",
      "epoch:0 81 loss:0.1009782999753952\n",
      "epoch:0 82 loss:0.10600084066390991\n",
      "epoch:0 83 loss:0.09896976500749588\n",
      "epoch:0 84 loss:0.09770488739013672\n",
      "epoch:0 85 loss:0.10220223665237427\n",
      "epoch:0 86 loss:0.10153001546859741\n",
      "epoch:0 87 loss:0.09615263342857361\n",
      "epoch:0 88 loss:0.09819352626800537\n",
      "epoch:0 89 loss:0.09860587120056152\n",
      "epoch:0 90 loss:0.0978749692440033\n",
      "epoch:0 91 loss:0.09786541759967804\n",
      "epoch:0 92 loss:0.10006427019834518\n",
      "epoch:0 93 loss:0.09646011143922806\n",
      "epoch:0 94 loss:0.0988805815577507\n",
      "epoch:0 95 loss:0.09844206273555756\n",
      "epoch:0 96 loss:0.09615969657897949\n",
      "epoch:0 97 loss:0.09749796986579895\n",
      "epoch:0 98 loss:0.09674300998449326\n",
      "epoch:0 99 loss:0.09925545752048492\n"
     ]
    }
   ],
   "source": [
    "disc_loss =0\n",
    "epoch=0\n",
    "for j in range(000,100):\n",
    "#for i in bad_case: \n",
    "    i = 124\n",
    "    disc_loss_cur =  generator_nn.train_on_batch(my_pic_b,my_pic_a)\n",
    "    disc_loss += disc_loss_cur\n",
    "    output_pic =  generator_nn.predict(my_pic_b)\n",
    "    fake_pic = generator_nn.predict(my_pic_b)\n",
    "    fake_pic = np.concatenate((fake_pic,output_pic,my_pic_a),1)\n",
    "    fake_pic = fake_pic * 127.5 + 127.5\n",
    "    cv2.imwrite(\"./pic_fuck/result_{}.jpg\".format(j),fake_pic[0])\n",
    "    print(\"epoch:{} {} loss:{}\".format(epoch,j,disc_loss_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(0,100):\n",
    "#for i in bad_case: \n",
    "    i = 124\n",
    "    disc_loss_cur =  generator_nn.train_on_batch(true_iamge[i:i+1],origin_image[i:i+1])\n",
    "    disc_loss += disc_loss_cur\n",
    "    output_pic =  generator_nn.predict(true_iamge[i:i+1])\n",
    "    fake_pic = generator_nn.predict(my_pic)\n",
    "    fake_pic = np.concatenate((fake_pic,output_pic,origin_image[i:i+1]),1)\n",
    "    fake_pic = fake_pic * 127.5 + 127.5\n",
    "    cv2.imwrite(\"./pic_fuck_191/result_{}.jpg\".format(j),fake_pic[0])\n",
    "    print(\"epoch:{} {} loss:{}\".format(epoch,j,disc_loss_cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/4.jpg\")\n",
    "my_pic=  my_pic[:,256:,:]\n",
    "my_pic = my_pic.reshape(1,256,256,3)\n",
    "my_pic = (my_pic - 127.5) / 127.5\n",
    "fake_pic = generator_nn.predict(my_pic)\n",
    "fake_pic = fake_pic * 127.5 + 127.5\n",
    "cv2.imwrite(\"result.jpg\".format(epoch),fake_pic[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "my_pic = cv2.imread(\"./facades/test/49.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "HSV = cv2.cvtColor(my_pic, cv2.COLOR_BGR2HSV)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
